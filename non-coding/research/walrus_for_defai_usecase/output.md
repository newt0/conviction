Understood. I will investigate how Walrus can be leveraged within the Sui ecosystem to support ConvictionFi and DeFAI use cases, focusing on integration with AI agents, metadata-driven DeFi strategies, and trigger-based execution workflows. I’ll prioritize official technical sources and GitHub repositories where available.

I’ll let you know once the findings are ready in a well-structured Markdown format.

# Leveraging Walrus in Sui for ConvictionFi/DeFAI Strategies

## 1. Technical Role of Walrus on Sui

**Walrus Overview and Architecture:** Walrus is a **decentralized storage and data availability protocol** built **on the Sui blockchain** to handle large binary files (“blobs”) efficiently. It operates via a network of dedicated storage nodes and uses Sui as a **coordination and payment layer**. When data is stored, Walrus uses an advanced erasure coding algorithm (named _RedStuff_, based on fountain codes) to split and encode the file into chunks, distributing them across many nodes. This approach provides high availability and fault tolerance: even if some nodes go offline or act maliciously, the file can be reconstructed from the remaining pieces. Notably, Walrus maintains storage cost at roughly **5× the original file size** (due to encoding overhead), which is far more efficient than naive full replication.

**Sui Integration and On-Chain Objects:** A key differentiator of Walrus is its tight integration with Sui’s smart contract platform, enabling **“programmable storage.”** Walrus leverages Sui’s object model: **storage space is represented as a resource object on Sui**, and each stored blob is tracked by a **Blob object on-chain**. This means when you upload data to Walrus, a Sui Move object is created to represent that blob. Smart contracts can interact with these blob objects – for example, a Move contract or NFT can **reference a blob’s object ID** and even query its availability or remaining storage time. This allows on-chain logic to incorporate off-chain data. For instance, **an NFT’s metadata image or strategy file can be stored in Walrus**, and a blob object linking that data to the NFT is created on Sui. This addresses the traditional NFT problem where token metadata lives off-chain – with Walrus, the off-chain data is verifiably tied to on-chain state, making NFTs on Sui **dynamic first-class Web3 assets**.

**Comparison with Arweave and Lit Protocol:** Walrus shares the goal of decentralized storage with networks like Arweave, but its design and capabilities differ significantly:

- **Arweave:** Arweave provides “permanent” storage by having (ideally) every miner store every file. This yields **high redundancy at high cost** – effectively up to _hundreds of copies_ of data across the network. In contrast, Walrus’s erasure-coded approach stores only **parts** of the data on each node for \~5× overhead, yet achieves a **low probability of data loss** comparable to Arweave’s redundancy. In fact, Walrus can be up to **100× more cost-efficient** than Filecoin or Arweave for large files. Another difference is **mutability**: Arweave is designed for permanent, unchangeable storage – once uploaded, data can’t be deleted or modified. Walrus allows **flexible data management**: users can choose to **delete or update blobs** when needed. This is important for use cases where data may be sensitive or needs to be revised (enterprises often require deletion or updates). Walrus achieves this without violating blockchain immutability – deleting a blob only removes the off-chain content; the on-chain transaction record and object remain for audit, and Sui’s storage fund can refund part of the deposit when data is deleted. In summary, Arweave offers one-time payment for perpetual storage (all data public, immutable) whereas Walrus offers **rentable storage with renewals**, lower cost, and on-chain programmability of data lifespan.

- **Lit Protocol:** Lit Protocol is an entirely different kind of network focusing on **decentralized encryption and access control** rather than bulk storage. Lit allows users to encrypt data and have it decrypted only under certain on-chain conditions (using threshold cryptography), often used to gate NFT content or manage keys. By itself Lit **does not store large content** persistently; instead, one might store an encrypted file on IPFS/Arweave and use Lit to manage who can decrypt it. Walrus, by design, stores data **in plaintext (unencrypted) and publicly** – all Walrus blobs are **publicly accessible by anyone** by default. This makes Walrus ideal for open data and content delivery (datasets, media files, prompts, etc.), but not for sensitive secrets unless the user encrypts them before storing. In use cases where confidentiality is needed, Walrus could complement networks like Lit: for example, a file could be encrypted, stored on Walrus, and the decryption key managed via Lit’s access control. However, **Walrus’s core strength is making data available and programmable** on Sui, not conditional privacy. It integrates deeply with Sui smart contracts – something Lit doesn’t specifically do on Sui – enabling on-chain programs to react to or require data availability. As Mysten Labs emphasizes, Walrus offers **fully programmable storage** that smart contracts can directly work with, enabling things like _dynamic NFTs and real-time data interaction_ that aren’t possible with static storage solutions. Lit Protocol, on the other hand, isn’t a storage provider and thus is typically complementary (providing trustless access control for data stored elsewhere).

**Read/Write Operations and Costs:** Using Walrus involves both off-chain and on-chain steps. To **write (store) data**, a developer typically uses the Walrus CLI or SDK to initiate an upload. The process is roughly:

1. **Reserve Space:** The user requests a certain storage amount (for a given number of epochs, i.e. time period). Walrus will lock the corresponding amount of SUI tokens into Sui’s storage fund (Sui charges an upfront storage fee based on data size). This makes every Walrus blob **contribute to Sui’s storage fund**, effectively removing some SUI from circulation while the data is stored (which has a deflationary effect on SUI’s supply). The user is issued a “storage resource” object representing the reserved space, which is a transferable Sui object (storage can be traded or split, thanks to Sui’s resource model).

2. **Register Blob:** The file is encoded (expanded \~5× with redundancy) and transmitted to the storage nodes. Walrus charges a fee in its native **WAL token** based on the encoded size (this compensates the storage nodes). The network aims to have all active storage nodes hold encoded chunks (Walrus uses a fast fountain code so that each node stores a unique piece, not full copies, maximizing redundancy with minimal overhead). After a successful upload, a **blob object** is created on Sui via a `register_blob` transaction, linking the content’s hash/ID, owner, and expiration details on-chain. This on-chain record means any contract or user can later verify the blob exists and see until what epoch it’s stored.

3. **Certification:** The Walrus storage nodes cryptographically **attest to the blob’s availability**. An aggregator (which could be the client or a Walrus “publisher” node) gathers proofs that enough nodes received the data. Then a `certify_blob` transaction on Sui finalizes the storage, confirming on-chain that the blob is successfully stored and available. At this point, the blob’s Sui object will show as **available for N epochs** (as paid for). The user can later extend the lifetime by calling `reserve_space` again for additional epochs (paying more WAL and a small SUI fee for the transaction), or let it expire (nodes may drop data after expiry).

To **read (retrieve) data**, anyone can query Walrus by the blob’s ID. Walrus provides a HTTP gateway and CLI command to fetch blobs. In practice, a client (like a dApp or an agent) will ask a Walrus aggregator node or any storage node for the blob. Because of the erasure-coded distribution, the node can retrieve chunks from multiple peers and reconstruct the file. Walrus is designed for **fast content delivery**, using techniques compatible with CDNs and caching. There is no on-chain transaction needed to read (data is pulled from the off-chain network), and currently all data is public, so no authorization is required.

**Cost Implications:** Storing data on Walrus incurs **two types of fees**: **WAL tokens** (to pay storage nodes for the service) and **SUI gas/deposit** (for on-chain operations and state). On Sui, storing any object requires a one-time storage fee proportional to size (which goes into the storage fund and is gradually paid out to validators). Walrus obeys this model – when you store a blob, you lock up SUI based on the blob’s encoded size. If you later delete the blob, Sui will refund some of that fee (minus what was paid to validators for the duration stored). This incentivizes freeing up space when data is no longer needed. On the WAL side, the amount of WAL spent depends on blob size and duration (longer storage or larger files cost more WAL). For small files, there is a fixed metadata overhead in the encoding (on the order of tens of MB) that makes them relatively more expensive per byte. In general, Walrus is optimized for **large blobs (e.g. >10MB)** where the 5× overhead dominates; small data (a few KB) would still incur a baseline cost due to network overhead.

Compared to alternatives, Walrus’s cost model is **usage-based and flexible**. Arweave requires a single upfront payment in AR that (in theory) covers forever storage; this can be costly for big files and you cannot reclaim it if you no longer need the data. Filecoin requires continuous payments to miners (deals that expire unless renewed) but doesn’t integrate with app logic easily. Walrus strikes a middle ground: **pay-as-you-go per epoch**, with easy renewal and the ability to reduce costs by deleting data when done. Studies have noted that Arweave’s full replication can impose **500× overhead costs**, whereas Walrus’s erasure approach only \~**4–5×** with negligible risk of loss. In summary, Walrus is _significantly cheaper_ and more scalable for large-scale data, while providing **strong guarantees of availability**. Furthermore, Walrus strengthens the Sui economy – every blob stored locks SUI in the storage fund (and a portion may be effectively burned), so heavy Walrus usage can make \$SUI scarcer over time. This symbiotic design shows that Walrus is not just an add-on, but a core part of Sui’s infrastructure vision.

## 2. Integration with AI Agents

Walrus was conceived with data-intensive applications in mind, and **AI agents** (autonomous bots powered by AI models) are a prime example. In the Sui ecosystem, teams are already leveraging Walrus to supercharge on-chain AI agents. For instance, **Talus** – a platform for on-chain AI – has selected Walrus as its default storage layer specifically to handle the data needs of its agents. There are several ways Walrus supports AI agents:

- **Storing Large AI Models and Prompts:** AI agents often rely on machine learning models (which can be hundreds of megabytes or more) or complex prompt files to guide their behavior. It’s impractical to store these directly on-chain. By using Walrus, an agent can offload model weights or lengthy prompt datasets to decentralized storage **without sacrificing speed**. The agent can **fetch and load its model from Walrus on demand**, as needed. According to Talus, an AI agent managing DeFi liquidity could store a large ML model on Walrus and **instantly fetch it** when rebalancing, allowing real-time reactions without clogging the chain. In other words, Walrus ensures that even heavy AI models are just a quick call away for the agent.

- **Persisting and Retrieving Dynamic Datasets:** AI agents continuously consume data – think of market feeds, social media updates, on-chain metrics, etc. Walrus enables agents to maintain their own knowledge base or frequently updated datasets in a decentralized way. An agent can write important observations or curated data to Walrus, and later read from it as context for decisions. Talus gives an example of an “AI Bae” agent that uses Walrus to store profiles or user data which evolve over time; the agent then **retrieves these profiles to inform its interactions**. Similarly, a DeFi agent could store a running log of market sentiment or price history on Walrus, creating a **persistent memory** that any instance of the agent (or even other agents) can reference. Walrus’s high throughput means even constantly-updated data sets (like hourly analytics) can be stored and retrieved efficiently.

- **Agent State and On-Chain History:** Beyond immediate decision data, AI agents may need to look at historical records or maintain state between sessions. Rather than relying on a centralized database, an agent can use Walrus as a **decentralized data journal**. For example, a fraud-detection agent might periodically dump summarized transaction patterns or alerts to Walrus. This creates a tamper-proof history that the agent can audit or even use to train new models. As noted, a Talus agent for fraud detection could **store historical transaction patterns on Walrus and analyze them in real-time** to spot anomalies. Because Walrus content is globally accessible, multiple agents or services can trust and utilize that stored history. In this way, Walrus serves as a **knowledge repository** or long-term memory for AI strategies operating on-chain.

- **Fast Access via Tools and APIs:** Integration-wise, Walrus is designed to be developer-friendly. Agents can interact with Walrus through **multiple interfaces**: a CLI, SDKs in various languages, or simple HTTP calls. For an AI agent (which might be written in Python or Node.js and possibly built on frameworks like LangChain), the HTTP/JSON API is very convenient – the agent can fetch a blob by sending an HTTP request to a Walrus endpoint or running a CLI command in the background. Walrus data can also be cached or delivered via CDN for low-latency reads, ensuring that agents get the information they need with minimal delay. In practice, once an agent knows the Blob ID (from the NFT or strategy object on Sui), it can retrieve the content in one call. This is fully **compatible with Sui’s off-chain agent frameworks**.

- **Persistent vs Ephemeral Memory:** In AI agent design, there’s often a notion of persistent memory (long-term context or data that survives agent restarts) versus ephemeral memory (transient working memory for a single run or conversation). Walrus enables a clear pattern for this: **use Walrus for persistent state** and offload ephemeral state to the agent’s in-memory variables or a cache. For instance, an agent’s core instructions (system prompt) and accumulated knowledge base can live in Walrus – so if the agent is restarted or multiple instances run, they all load the same baseline context. Meanwhile, ephemeral data (like the current conversation with a user, or the last hour’s sensor readings that don’t need to be saved) can be kept in the agent’s runtime and not written to Walrus. This separation keeps Walrus storage efficient and reserved for high-value data, while giving agents the ability to “pick up where they left off” by re-reading Walrus on startup. Importantly, any off-chain agent can be programmed to periodically push important new state to Walrus (e.g. end-of-day summary) to promote it from ephemeral to persistent. This pattern is more robust than keeping state only in-memory, and more scalable than constantly writing to on-chain storage.

**Sui Agent Kit Compatibility:** The Sui ecosystem has developed tooling to ease the connection between AI agents and on-chain activity – notably the **Sui Agent Kit** (from projects like Nimbus/Pelagos). Sui Agent Kit provides an SDK for agents to autonomously perform on-chain actions (trading, lending, staking, etc.) by abstracting Sui transactions in a format that AI models or scripts can trigger. Walrus complements such kits by providing the **data layer** those agents require. In a typical flow, Sui Agent Kit would handle blockchain interactions (e.g. constructing and signing a transaction to swap tokens), while Walrus would handle data interactions (e.g. retrieving the agent’s strategy parameters or the latest market data needed to decide that a swap is necessary). Because Walrus and Sui are integrated, an agent can even use on-chain queries to verify data availability (a Move contract could enforce that a required blob exists before a transaction executes). But more simply, the agent can trust that any Blob ID in a Sui object is retrievable via Walrus network calls.

It’s worth noting that the **Sui Foundation and Mysten Labs actively encourage** this agent+Walrus paradigm. Talus’s integration is a proof-of-concept: their on-chain agent framework Nexus uses Sui for high-speed execution and Walrus for storage, enabling “real-time AI automation” in areas like DeFi (sometimes dubbed **DeFAI**). With Sui’s high throughput, an agent can react quickly (Sui finality \~ sub-second), and with Walrus’s bandwidth, it can ingest and output large data as needed. This combination unlocks scenarios like on-chain trading bots guided by off-chain AI: the AI can process complex data or run heavy algorithms off-chain, but still store its knowledge or signals on Walrus and execute final trades on Sui. As a result, the **feasibility of AI agents driving on-chain activity** (like ConvictionFi strategies) is very high on Sui. The infrastructure (Agent Kit, Walrus, fast execution) is in place to support such autonomous agents.

In summary, Walrus gives AI agents **persistent, fast, and scalable I/O** for data, while Sui gives them a playground for secure execution of financial logic. Agents can read from Walrus-stored prompts or target lists at startup, monitor live data feeds off-chain, then call Sui when triggers fire – a design that leverages the best of off-chain computation and on-chain settlement.

## 3. Metadata-Driven DeFi Strategy via NFTs and Walrus

A core idea behind **ConvictionFi/DeFAI** is to encode a trading or investment strategy in a form that an AI or algorithm can execute autonomously. Sui’s object model and Walrus’s storage capabilities make it possible to package a strategy as an **NFT with rich metadata**, where the metadata lives on Walrus. The NFT acts as a handle or **strategy token**, and its metadata contains all the parameters that define the strategy. This section examines the feasibility of storing various strategy components inside an NFT’s metadata and how an agent would use them:

- **Investment Theme:** This is a descriptive tag or category for the strategy’s focus, e.g. `"$TRUMP"` or `"AI Stocks"`. It indicates the narrative or market sector the strategy is targeting. Storing this in metadata is straightforward – it’s just a string or keyword. The theme can guide the agent on what type of data to watch (tweets about a certain person, or stock prices in a sector) and possibly which assets to trade (coins related to the theme). Having it on-chain (or in Walrus metadata) also makes it transparent to users what the strategy is about. An NFT’s JSON metadata could include a field like `"theme": "US Election 2024 (Trump)"`. This is small in size and perfectly suited for Walrus (it could equally be on-chain as a Move string, but keeping it in the off-chain JSON keeps all strategy info in one place). The agent will read this theme and could log it or use it to dynamically adjust its behavior (e.g. if theme == "AI", maybe load a certain ML model specialized for AI markets).

- **System Prompt:** In AI terms, a _system prompt_ is a set of instructions or context given to an AI model to guide its responses. In our case, this could be a written description of the strategy’s logic or rules, which an LLM-based agent would use to stay on script. For example, a system prompt might say: _"You are an expert trading agent focusing on politics-driven markets. Always check Trump’s social media for signals. If he mentions any publicly traded company, consider it as a buy signal for related assets..."_ and so on. This could be a **large block of text** (several KBs or more), which is fine to store on Walrus. Sui on-chain data has size limits and costs that would discourage storing long prompts directly in the NFT object, but Walrus can handle it easily (even multi-megabyte prompts are possible, though likely not needed). The NFT’s metadata JSON can have a field `"system_prompt": "<text blob or reference>"`. The agent, upon initialization, fetches this prompt from Walrus and feeds it into its AI model (e.g. an OpenAI API call or a local LLM) as the system role. This effectively **bakes the strategy’s philosophy and constraints into the AI’s decision-making**. Because it’s stored in Walrus, the prompt can be as detailed as necessary (including examples, lengthy instructions, etc.) without worrying about on-chain storage costs. It’s important to note that since Walrus data is public, if the strategy prompt is proprietary logic, the creator might consider obfuscating or encrypting it. But if it’s meant to be a transparent, community-auditable strategy, storing it in plaintext is actually a benefit (anyone can see the rules the agent is supposed to follow).

- **Watch Targets:** These are the specific data sources or indicators the strategy will monitor. They could include **off-chain sources** like Twitter accounts, news feeds, RSS APIs, or **on-chain events** like price oracles, DEX trade volumes, etc. Inside NFT metadata, this can be represented as a list or array of targets. For example: `"watch_targets": ["twitter.com/realDonaldTrump", "newsapi.org/politics RSS", "Sui:0x...Oracle::BTC_USD"]`. Each target could have a type (social vs price feed vs on-chain) and parameters (like update frequency). Storing this list in Walrus is very feasible – it’s structured data (JSON) of relatively small size. The agent will parse this list and set up the appropriate monitors. For a Twitter target, it might use the Twitter API or a scraper to watch for new tweets from that account. For an API target, it might poll an endpoint periodically. For an on-chain target, it could subscribe to Sui event streams or use an RPC to get updates. By having the list in the NFT metadata, **the strategy can be easily understood and even modified** by changing the targets. If tomorrow the strategy needs to watch a new account or a different oracle, one could update the metadata blob (issuing a new Walrus blob and updating the NFT’s reference to point to it). This is simpler than redeploying a contract. It also externalizes the configuration from the agent code – meaning the same agent program could run multiple NFTs with different target lists just by reading their metadata.

- **Execution Triggers:** These define _when and what to execute_ – the conditions under which the agent should act, and possibly what action to take. Triggers might be simple thresholds or complex logic. Examples: _“If any target’s sentiment score goes above 0.8, allocate 10% of portfolio to associated asset”_, or _“If price of token X drops by 5% within 1 hour, sell half the holdings”_. In metadata, triggers could be represented in a structured form (pseudo-code, logical rules, or a DSL). For instance, a JSON trigger might be:

  ```json
  {
    "condition": "price('X') < 0.95 * prev_price('X')",
    "action": "SELL",
    "amount": "50%"
  }
  ```

  or

  ```json
  {
    "condition": "keyword('merger') appears in feed('Reuters')",
    "action": "BUY_ASSET",
    "asset": "MergerArbToken",
    "budget": "100 USD"
  }
  ```

  The precise schema can vary, but the idea is the NFT metadata holds the **logic blueprint** that the agent will follow. An AI agent could even hold these triggers as part of its prompt (like instructions: “If you see condition X, then do Y”), or a simpler script-based agent could directly evaluate these JSON rules. Walrus is well-suited to store this because triggers could get lengthy or numerous. Also, being able to update triggers is valuable – if a strategy is refined, you can publish new triggers to Walrus and update the NFT. The agent, if written to handle version updates, would then adapt on the fly. This pattern effectively allows **“strategy as code”** stored in metadata, without needing to write new on-chain code for each tweak. It’s a very flexible approach.

All the above components can be bundled in a single Walrus-stored metadata file (e.g. a JSON or YAML) that the NFT references. **This is highly feasible on Sui using Walrus**, and in fact aligns with what Sui’s dynamic objects enable. As one Sui builder noted, because Sui Move NFTs are objects, they are far more dynamic than static ERC-721 tokens – _“Move-based NFTs… enable dynamic and composable NFTs… Add in programmable storage, and the attached NFT metadata becomes just as dynamic and responsive.”_. Walrus is the “programmable storage” being referred to in that quote. In practice, the NFT might contain a field like `metadata_blob: 0x<WalrusBlobID>` (or a URL pointing to a Walrus gateway with that blob). The presence of Walrus means the NFT’s metadata can change over time (by updating the blob reference), enabling strategies that evolve or react to new conditions.

**Agent Behavior Using Metadata:** When an off-chain agent is tasked with running a ConvictionFi strategy NFT, its first step is to **interpret the NFT’s metadata**. This typically involves:

1. **Fetching the Metadata:** The agent sees the NFT on-chain (perhaps the NFT is passed to the agent, or the agent continuously scans for new strategy NFTs). It extracts the Walrus blob ID or link from the NFT object. Then it calls Walrus (via HTTP or CLI) to retrieve the metadata JSON file. This file contains all the fields discussed (theme, prompt, targets, triggers, etc.). The agent might verify the integrity (Walrus ensures data availability, and hashes can be checked if included) and then parse this JSON.

2. **Configuration:** Based on the metadata, the agent **configures itself**. If there’s a system prompt and the agent uses an LLM, it will load that prompt into the LLM’s context so that all subsequent decisions adhere to those instructions. The agent will set up connections to each _watch target_ – e.g., open a stream or schedule API calls for each listed source. It may also allocate resources or models as needed (for example, if the theme is "AI stocks", the agent might load a specific list of stock tickers or a sector-specific model – this can be encoded in the prompt or targets). Essentially, the metadata tells the agent **what to pay attention to and how to behave**.

3. **Main Loop (Observation and Decision):** The agent then enters its monitoring loop. It continuously gathers data from the watch targets. Because the targets can be off-chain, the agent often runs as a daemon process in a cloud or local environment with internet access (this is the off-chain component). As new data comes in (e.g., a tweet from the watched account, or a price feed tick), the agent may update an internal state or feed the information into an AI model for analysis. In some designs, the agent could even store intermediate observations back to Walrus for transparency or later use (though this would be optional, as it costs WAL/SUI – likely only key events or periodic snapshots would be stored to avoid spamming storage).

4. **Trigger Evaluation:** At each iteration (or whenever new data arrives), the agent checks the **execution triggers** from the metadata. If the trigger conditions are written in a machine-readable form, the agent’s code can evaluate them directly against the current data. If they are embedded in an AI prompt, the agent might ask the LLM to interpret whether a condition is met (less deterministic, but possible). For example, the agent might have logic: _for each trigger in triggers list, if evaluate(trigger.condition) is true, then execute trigger.action_. The triggers could involve thresholds (numeric comparisons), event occurrence (keyword detection, etc.), or time-based rules. The agent keeps track of whether triggers have fired to avoid repetition if they are one-time or have cooldowns (this could also be defined in metadata).

5. **On-Chain Execution:** When a trigger condition is satisfied, the agent proceeds to carry out the specified action **on-chain**. This is where Sui Agent Kit or custom integration comes in – the agent will craft the appropriate Sui transaction. Depending on the strategy, this could mean: transferring funds, swapping tokens on a DEX, minting or burning assets, rebalancing a portfolio, or interacting with a specific DeFi protocol. The NFT strategy might be associated with a particular on-chain **vault or account** that holds funds to deploy. For instance, owning the strategy NFT could entitle the holder to deposit some capital into a linked smart contract, and the agent is authorized (perhaps via the NFT or a designated key) to trade on behalf of that contract. There are multiple design options here, but one simple approach is the agent itself holds the private key to the strategy’s fund account (given by the user under trust, or generated and escrowed via MPC, etc.). Another approach: the NFT could have an associated Move module that allows certain trusted contracts to execute trades under conditions (though off-chain agent will usually be the one to call it). In the initial implementations, it’s likely the agent just has the keys or credentials needed to execute the trades directly.

6. **Transaction and Feedback:** The agent signs and submits the Sui transaction. Thanks to Sui’s high throughput, this can be confirmed in a few seconds or less, bringing the on-chain state in line with the strategy’s intent. The agent then might log the outcome. If the design requires it, the agent could also update the NFT’s metadata or another Walrus blob with the result of the action (for example, recording that “Trade executed: Sold 50% at \$X price”). However, updating the NFT metadata on-chain would mean creating a new blob and calling an update method – not all implementations will do this due to cost. Many strategies might be content with the on-chain transaction logs as the record of actions (since all trades will appear on-chain anyway).

7. **Lifecycle:** The agent continues monitoring after an action. Some triggers might be one-off (the strategy could specify to stop after one execution or require manual reset). Others might be continuous (e.g. “do this every time price drops 5%”). The NFT metadata can include a parameter for strategy frequency or end conditions. Eventually, the user might decide to stop the strategy – perhaps by burning the NFT or calling a function to deactivate it. In that case, the agent would detect that state (maybe the NFT gets a flag flipped on-chain) and gracefully stop monitoring.

**Pros of this Workflow:** This NFT + Walrus + agent architecture offers **extreme flexibility and composability**:

- _Separation of Concerns:_ The strategy logic (metadata) is separated from the execution engine (agent code) and the financial infrastructure (smart contracts). This means you can update the strategy without redeploying contracts or rewriting the agent code – just change the data. Multiple strategies can run on the same agent framework, simply by loading different NFTs.

- _Human-Readable Strategies:_ By encoding triggers and prompts in metadata, strategies become more transparent. Investors or regulators could inspect an NFT’s Walrus metadata to understand the general behavior of the agent (assuming it’s not encrypted). This is unlike a black-box proprietary bot where you have no clue what rules it follows. Here the rules are literally part of the asset.

- _Dynamic and Upgradable:_ **Dynamic NFTs** are enabled via Walrus. Since the metadata is off-chain, one can update the content (by issuing a new blob and updating the NFT’s reference, if the NFT contract permits owner updates). TradePort’s team highlights that on Sui, NFTs and storage can be dynamic – _“Sui enables dynamic and composable NFTs… Walrus makes the attached NFT metadata just as dynamic and responsive.”_. This dynamic nature is a game-changer for on-chain strategies: you could adjust a running strategy’s parameters in real-time by pushing a new config file, rather than stopping it entirely.

- _Scalability:_ Offloading heavy computation (data analysis, AI model inference) to the agent off-chain means the on-chain part remains light and scalable. Sui’s role is mostly to keep a record of what strategy is active and to execute the final transactions. Hundreds of such strategy agents could run in parallel without burdening the blockchain with anything except the resulting transactions (which are no heavier than normal user trades). Walrus ensures that even if each strategy has large data (AI models, big prompts, etc.), the chain isn’t storing all that – only the references and small objects. This hybrid model (off-chain agent + on-chain effects) is far more scalable than trying to do complex strategy logic in on-chain smart contracts.

- _Composable DeFi:_ Because the strategies are NFTs, one can envision secondary markets and additional composability. For example, a user could **buy or sell a strategy NFT** (effectively buying the “trading bot” and its configuration). If the strategy NFT is controlling a vault of funds, maybe ownership transfer also moves the claim on that vault. One could also use the NFT as collateral (though assessing its risk is complex, it could have a performance history attached in metadata). Additionally, other smart contracts could read the NFT’s blob to integrate with it – e.g., a dashboard contract could display the strategy’s theme and status on-chain by reading the Walrus blob’s hash or a summary field that is stored on-chain. In short, the strategy becomes a **composable on-chain object** rather than just off-chain code.

**Potential Challenges and Considerations:**

While the approach is powerful, it’s worth noting a few challenges:

- _Trust in the Agent:_ The whole system relies on an off-chain agent executing the strategy as specified. If the agent is run by the strategy owner themselves, this is fine (they trust their own bot). But if it’s a third-party service (like Talus or another network of bots), users need to trust that the agent will faithfully follow the NFT’s metadata rules and not act maliciously. Decentralizing the agent layer or using cryptographic assurances (like having the agent post a bond on-chain or using multiple agents for redundancy) could be ways to increase trust. In early stages, it might be semi-trusted: e.g., the user runs the agent on their own machine, or a reputable service does it with accountability. Eventually, one could imagine a decentralized network of keeper bots that pick up strategy NFTs and execute them for a fee, somewhat like how KeeperDAO or Gelato work on Ethereum for generic tasks.

- _Data Reliability:_ The agent relies on off-chain data sources that could be unreliable or manipulated (e.g. fake news, Twitter API limits, etc.). If someone tweets false information and the agent isn’t sophisticated, it might trigger trades on bad info. Mitigation requires robust data handling – perhaps using multiple sources or on-chain oracles for confirmation. Also, rate limiting and error handling need to be in the agent: APIs can fail or get rate-limited, so the agent must be resilient to missing data or delays.

- _Performance and Latency:_ While Sui and Walrus are high-performance, the overall loop includes internet data fetching and computation. There will be some latency between a trigger condition happening and the execution on-chain. For many strategies (e.g., event-driven trading) a delay of a few seconds to a minute is fine. But for ultra-HFT (high-frequency trading), this wouldn’t compete with on-chain flash loans or MEV bots that react in milliseconds. However, HFT is not really the domain of these kinds of AI strategies – the focus is more on _conviction_, i.e., acting on fundamental or sentiment shifts, not beating someone by a millisecond. So the latency is a trade-off for having more complex logic. Sui’s fast finality does help minimize the window of uncertainty once a decision to act is made, which is a plus.

- _Complexity:_ The system is complex to implement correctly. One has to orchestrate NFT creation, Walrus storage operations, running the agent, and ensuring security at each step. There are many “moving parts,” and each needs to be robust (for example, if Walrus blob expires because the owner forgot to extend it, the agent could lose access to metadata – so perhaps the agent or another service should automatically extend Walrus blobs using WAL and SUI the user has set aside). It’s important to identify the **potential bottlenecks**: one could be the Walrus network bandwidth if an agent tries to retrieve a very large model frequently (caching should be used – the agent can store the model locally after first download). Another bottleneck might be the number of strategies one agent process can handle – if one agent is running 100 NFTs, it needs to juggle a lot of asynchronous data streams; beyond a point, you’d distribute across multiple agent instances or machines. Fortunately, cloud-native design (microservices) can be applied since agents are off-chain programs.

- _Security:_ Both the NFT metadata and the agent logic can be targets for attackers. If someone maliciously alters the Walrus data (which they shouldn’t be able to unless they compromise the owner’s key, because updating the blob object requires an on-chain transaction by the owner or Walrus expiration), the agent could be tricked. The agent should always verify it’s fetching the correct blob (checking the blob’s content hash if provided by the NFT). Also, storing secrets (like API keys or private keys) in NFT metadata would be a **bad idea** since it’s public – those should remain off-chain (or encrypted via something like Lit as earlier). Generally, the strategy metadata should not contain private info, only the strategy logic and public references.

Despite these challenges, **the technical feasibility is sound**. In fact, the described workflow is not just theoretical: the Sui/Talus team and others are actively working on frameworks to make deploying such agent-driven strategies easier. The combination of **NFTs + Walrus + off-chain agents** essentially creates a new primitive for on-chain finance: strategies that are _tokenized (NFT), data-rich (Walrus), and autonomous (AI agent)_.

## 4. ConvictionFi Workflow Architecture

Let’s put it all together into a concrete **ConvictionFi workflow**. “ConvictionFi” in this context implies an AI-driven DeFi strategy that operates with conviction on certain signals (like a thematic investment thesis). The high-level architecture involves both on-chain components (Sui contracts, NFTs, transactions) and off-chain components (the agent and data feeds). Below is a step-by-step pipeline from creating a strategy to automated execution:

1. **Strategy NFT Minting:** The process begins with the user (or strategy creator) **minting an NFT** on Sui that represents the strategy. This NFT can be a custom Move struct defined in a DeFi-AI package, including fields like `owner`, maybe a reference to a vault or fund that will be used, and critically a field for `metadata_blob` (initially empty or set to some default). Minting the NFT establishes an on-chain identity for the strategy – at this point it might just be a shell awaiting configuration. The NFT can also store small pieces of info like a name or ID for human identification. For example, you call a Move function like `mint_strategy_nft(owner, name)` and get back object ID `0xStrategyNFT1`. Initially, it might not yet be active.

2. **Writing Strategy Metadata to Walrus:** Next, the strategy creator composes the **strategy metadata** file containing all the details (theme, prompt, targets, triggers, etc., as discussed in Section 3). They then use the Walrus client to **upload this metadata file**. Suppose the JSON is 50 KB – Walrus will create an erasure-coded blob maybe \~250 KB stored across nodes, and register a blob object on Sui. The creator pays a bit of WAL and SUI (negligible for a small file; most cost might be the fixed metadata overhead, but 50 KB is tiny relative to Walrus’s scale). Let’s say the resulting **Blob object ID** on Sui is `0xBlobABC` and it is certified stored for, e.g., 100 epochs (could be a long time, since text data doesn’t take much space, the cost is low, they might as well store it for months or years).

3. **Linking NFT to Walrus Blob:** With the blob ID in hand, the creator now performs an **update transaction on the NFT** to link it to the metadata blob. This could be implemented as a Move function like `update_strategy_metadata(nft: StrategyNFT, blob: Blob)` which sets the NFT’s `metadata_blob` field to point to `0xBlobABC` (and perhaps stores a hash or version for verification). Because the NFT and Blob are both objects on Sui, this update is an atomic on-chain operation. After this, the NFT is effectively loaded with its strategy. This step might also flip an `is_active` flag on the NFT or emit an event that a new strategy is configured.

4. **Agent Initialization:** Now comes the off-chain component. There needs to be an **AI agent service** that will take charge of this strategy. Depending on the setup:

   - If the user is running their own agent, they would start their agent software and instruct it to load their NFT (perhaps by inputting the NFT ID or having the agent query the chain for NFTs owned by the user).
   - If using a hosted service (like Talus Nexus), the platform might automatically detect the new NFT (especially if an event was emitted or if the NFT was minted via their UI) and spin up an agent for it. There could even be a registry on-chain of active strategy NFTs that agents watch.

   In any case, the agent obtains the NFT’s ID and from that uses a Sui RPC to fetch the NFT object data. It sees the `metadata_blob: 0xBlobABC` reference. The agent then calls Walrus (via the Walrus SDK or a simple HTTP GET) to fetch the actual metadata content associated with `0xBlobABC`. It’s likely JSON, so the agent parses it. This contains all the instructions for the agent as described. The agent might log “Loaded strategy NFT 0xStrategyNFT1 with theme X, watching Y, triggers Z, etc.” for debugging.

5. **Agent Monitoring Loop:** The agent begins executing the strategy. This involves:

   - **Setting up data feeds**: e.g., open a WebSocket or long poll for each Twitter account, set up a scheduler to call price APIs every minute, subscribe to on-chain events if needed (Sui could have price oracles or just use off-chain oracles).
   - **Priming the AI model**: If using an LLM for complex decision-making, the agent loads the system prompt from metadata into the model’s context. It might also initialize any other needed modules (e.g., technical indicator calculators if triggers involve TA, etc.).
   - **Idle until event**: The agent mostly waits for new data or a time interval. When new data arrives or a check interval triggers, it processes the input through its logic or AI. For instance, if a tweet comes in, and the system prompt instructs “when a tweet containing certain keywords appears, consider doing X”, the agent might run an LLM prompt like: _“Given the strategy rules and this new tweet: '<tweet text>', should we execute any action?”_ The LLM might answer yes/no and which trigger. Or a simpler agent just checks if the tweet text matches any trigger regex from metadata.

   This loop continues indefinitely. The **memory patterns** discussed earlier come into play here: the agent might accumulate short-term memory (like “the last tweet seen”) which it doesn’t log to Walrus every time, to reduce overhead. But it knows it can refer back to the Walrus metadata anytime if it needs to recall the base instructions.

6. **Trigger Detection and On-Chain Execution:** Suppose one of the conditions is met – e.g., the agent detects that _“Keyword 'merger' detected in Reuters feed and stock X is in theme, trigger says BUY_ASSET”_. The agent confirms the criteria and then prepares to execute. Now it will formulate a Sui transaction. If the strategy NFT is controlling funds in a DeFi protocol, the agent might call a Move contract function associated with the NFT (for example, a function like `StrategyVault::execute_trade(nft_id, trade_params)` that can only be called by the NFT owner or an authorized agent). However, more straightforwardly, perhaps the user provided the agent with a direct key to a trading account. In that case, the agent uses Sui’s SDK (which Sui Agent Kit wraps conveniently) to craft a transaction – e.g., a swap on the DeepBook DEX from one asset to another, or a series of transfers. The agent signs this transaction using the account’s key (which could be the same as the NFT owner’s key, or a delegated key given to the agent).

   The transaction is then submitted to the Sui network. Thanks to Sui’s parallel execution, even complex multi-leg transactions (if within one contract call) are executed quickly. The result might be that the user’s portfolio is updated or the strategy NFT’s associated vault now holds a new asset. Importantly, because this is an on-chain transaction, it leaves a **transparent record**. Anyone can see that, at time T, NFT strategy X triggered and executed a trade (the NFT ID might even be part of the transaction events or logs if the contract uses it). This provides auditability.

7. **Feedback and Continuation:** After execution, the agent can continue running. The NFT metadata might specify whether the strategy is one-and-done or continuous. If one-time, the agent might then halt or mark this strategy as completed (optionally, the NFT could even burn itself or change a state on-chain like `completed = true`). If continuous, the agent goes back to watching for the next trigger.

   To illustrate a concrete **ConvictionFi example**: Consider a strategy NFT themed “**AI Startup Sentiment**” that watches a specific tech news feed and a list of crypto tokens of AI-related projects. Its trigger: if **any news of a major AI startup IPO or funding** appears (detected via keywords like “raises \$100M” or “files IPO” in the feed), then **buy the top 3 AI tokens** with equal allocation using the funds available. The NFT holds this logic. The agent monitors a news API and perhaps price data for those tokens. When OpenAI (for instance) announces a new breakthrough or a big funding round, the agent sees the news headline, matches the trigger condition, and executes buy orders for tokens like FET, AGIX, etc., on a Sui DEX. This happens automatically, maybe faster than many human traders reading the news. The user who owns that NFT has now automatically invested based on the “conviction” encoded in the NFT. They could later sell the tokens manually or even encode a take-profit trigger in the same NFT.

**Pros/Cons Recap:**

_Advantages:_ This workflow allows complex strategies to live **entirely on-chain in representation but off-chain in execution**, marrying transparency with flexibility. The user does not need to trust a human fund manager – they trust an algorithm that is largely public. The **autonomy** means 24/7 operation without needing the user to manually intervene (which is great for reacting to global events). Also, since strategies are NFTs, they could be **fractionalized or shared** (in the future, maybe multiple people could pool funds into one strategy NFT run by a community-chosen agent).

The on-chain execution ensures that whenever the agent acts, it’s recorded and (if coded so) enforceable. For instance, if the agent tried to do something not allowed (like withdraw funds to an unauthorized address), a well-designed vault contract would reject it – the agent is powerful but still bound by the smart contracts it interacts with. Thus we get a balance of **off-chain intelligence and on-chain security**.

_Potential Bottlenecks:_ We touched on technical bottlenecks (latency, data reliability). Another bottleneck might be **Walrus write throughput** if, say, thousands of strategies tried to update their metadata simultaneously or store large datasets. However, Walrus is built for high throughput and can handle many parallel writes (Sui’s scalability and the storage node architecture should allow a lot of concurrency). Reading is even easier to scale via CDNs. So, Walrus is unlikely to be a bottleneck unless misused (like continuously writing every second, which isn’t typical for strategy metadata). The **agent itself** could be a bottleneck – if a single agent service tries to handle too many NFTs, it might lag in reacting. The solution is simply to scale out horizontally (run more agent instances), which is doable since each NFT can be managed independently.

Another consideration: **cost bottlenecks**. Each strategy execution costs SUI gas. If a strategy triggers extremely often (say high-frequency), those gas fees could add up. Sui’s low fees mitigate this, but it’s not feeless. If a user has a very active strategy, they must ensure they have enough SUI for gas in their account or in the strategy vault. This is similar to any DeFi bot: e.g., on Ethereum, running a trading bot would incur gas costs that eat into profits. On Sui it’s cheaper, but not zero. So extremely fine-grained strategies might not be profitable after fees – which again implies these ConvictionFi strategies will aim for quality of signals over quantity of trades.

**Overall Feasibility:** The architecture described is quite feasible with current technology. In fact, early versions are **already being implemented**. The Talus platform suggests a pipeline where developers can “launch tokenized AI agents, automate trading strategies, and engineer autonomous economies” – which is essentially describing strategy NFTs (tokenized agents) plus automation. They highlight that Sui’s performance and Walrus’s storage enable AI agents to operate with on-chain verifiability and real-time decision making. So this isn’t science fiction; it’s in progress.

To implement a ConvictionFi strategy on Sui today, one would use: Sui Move for NFT and possibly a vault contract, Walrus for metadata (which as of Q1 2025 is live and functional on mainnet), and an off-chain agent using something like Sui Agent Kit or custom code. Each piece individually works, and combining them is the next step. There may be some tooling to improve (for example, easier integration of Walrus reads in agent SDKs, or templates for strategy metadata formats), but those are being actively worked on in the community.

## 5. Real-World Adoption and Development Activity

Walrus is a **new but rapidly growing** part of the Sui ecosystem, and we’re already seeing significant adoption in multiple domains relevant to ConvictionFi/DeFAI. Below are some examples and indicators of Walrus’s real-world use and support:

- **Dynamic NFT Platforms (TradePort):** **TradePort**, the largest NFT marketplace on Sui, announced that it is **using Walrus to store metadata for all its Move-based NFTs**. This means any NFT created via TradePort’s launchpad or traded on their platform can leverage Walrus for images, traits, etc. TradePort’s team has been enthusiastic about the **programmability** this unlocks. In a press release, their co-founder highlighted that on Move blockchains like Sui, NFTs are inherently more dynamic, and with Walrus _“the attached NFT metadata becomes just as dynamic and responsive”_, enabling use cases far beyond static JPEGs. This is a strong vote of confidence that Walrus is production-ready for handling potentially millions of NFT metadata lookups and updates. For ConvictionFi, this is encouraging because it shows the same mechanism (NFT + Walrus metadata) is already in real use for NFTs – our strategy NFTs would be a specialized case of that general pattern.

- **On-Chain AI Agents (Talus/Turbos):** We’ve referenced **Talus** a few times – this is a platform focusing on on-chain AI agents for DeFi, gaming, social, etc. Talus has partnered with Sui, and notably, **Talus chose Walrus as its default decentralized storage** for their AI agents’ needs. The reasoning is precisely the use cases we discussed: storing AI models, datasets, and agent state off-chain but in a decentralized way. According to the Sui Foundation’s announcement, Walrus can support Talus agents in storing things like large ML models (to keep the chain from slowing down) and retrieving datasets like market sentiment in real-time. Talus is essentially pioneering the DeFAI (Decentralized Finance AI) space on Sui, showing how automated agents can manage liquidity or other financial tasks. Their use of Walrus is a **direct validation** of Walrus’s importance for ConvictionFi scenarios. If you consider a ConvictionFi strategy NFT, Talus provides a blueprint of how an agent would operate it, and Walrus is part of that blueprint.

- **Enterprise and Web2 Integrations:** Even during testnet, Walrus garnered interest outside the immediate Sui NFT/agent circles. For example, **Decrypt Media**, a well-known crypto news outlet, explored Walrus for content storage (perhaps to decentralize their media hosting). Also, **Akord** (a decentralized file storage/sharing app) started integrating Walrus as a backend. These indicate that Walrus’s technology (erasure-coded storage + Sui) is seen as robust enough for production data needs. Another partner mentioned is **Tusky**, which appears to be a service planning to offer long-term storage using Walrus (allowing users to prepay for storage over time). Tusky is likely building a user-friendly front-end or tooling on top of Walrus. This kind of infrastructure and middleware support signals a healthy ecosystem – developers are making it easier to use Walrus, which in turn will make it easier for our ConvictionFi use case to be implemented by others.

- **Hackathons and Community Projects:** The Sui Foundation and Mysten Labs have heavily promoted Walrus in developer events. In late 2024, they ran _“Breaking the Ice”_, the Walrus Devnet Hackathon, which drew nearly **300 developers** and over **60 project submissions** built on Walrus. Ultimately 40 projects were shortlisted and 10 winners chosen, showcasing a broad range of use cases – _“from file-sharing services and games to developer tools for Walrus”_. This breadth is important: it means Walrus isn’t a niche tool, but a general platform that people applied to many ideas. Some hackathon projects likely touched on **social networks (SocialFi)** – e.g., one known project was “SuiMeet,” a Web3 matchmaking/dating app where each user profile was an NFT stored as a Walrus site (a personal webpage on Walrus). That demonstrates social data (profiles, messages) being stored via Walrus. We also saw likely game projects using Walrus for assets or game state. While these aren’t directly ConvictionFi, they stress-tested Walrus in creative ways and provided feedback. The hackathon’s emphasis on **“programmable storage track”** continued into Sui’s global hackathon (Sui Overflow 2025), with Walrus being a dedicated category. This indicates strong **support from the Sui Foundation** – they are incentivizing developers to build with Walrus, even providing prize tracks and presumably technical guidance. For a ConvictionFi developer, this environment means resources and community knowledge are available for building such systems on Walrus.

- **Mainnet Launch and \$WAL Token:** Walrus launched its **mainnet in late Q1 2025** (March 27, 2025), which included the release of the \$WAL token for staking and payments. The launch was backed by major investors and came with a large airdrop to encourage adoption. Within a short time, WAL was listed and the token saw significant interest (one report noted WAL’s price rising on news of AI and NFT use cases fueling demand). While token price is not our focus, it reflects that the market sees **Walrus as a core piece of the Sui ecosystem with real utility**. Mysten Labs themselves have stated Walrus will become one of the _“most critical protocols for Sui”_ long-term, not just an experiment. They envision Sui covering all bases of Web3 infrastructure (execution, storage, communication), with Walrus covering the storage pillar. This institutional commitment means developers can be confident Walrus will be maintained and improved over time (updates, support, etc.).

- **Projects in Pipeline:** Beyond those already live, there are hints of upcoming projects that combine AI and Walrus. For example, there is talk of **AI DAOs** and autonomous economic agents in Sui’s roadmap (some terms like GameFAI, SocialFAI were mentioned). It’s reasonable to expect that some of these decentralized AI projects will utilize the same pattern: NFT + Walrus + off-chain agent. If any specific project names drop (e.g., perhaps someone launching a decentralized hedge fund represented by NFTs), Walrus will likely be involved. The architecture is general enough to apply to many “store logic off-chain, act on-chain” scenarios (could be used in automated insurance claims, IoT data triggering payments, etc., in addition to trading).

In conclusion, Walrus is **gaining real traction** on Sui, from NFT marketplaces to AI agent platforms. The Sui Foundation actively supports it through hackathons and ecosystem funds, and Mysten Labs continues to drive its development (they even published a detailed whitepaper and open-sourced many parts of it on GitHub). For a ConvictionFi use case, this is great news: the tools and examples are there to follow. A developer can point to TradePort’s use of Walrus as proof that storing critical on-chain asset metadata in Walrus is viable and performant. They can point to Talus as proof that off-chain agents can reliably fetch from Walrus to inform on-chain actions. And if they need help or to hire talent, there’s now a pool of developers experienced with Walrus from these hackathons and projects.

**Emphasis on Technical Feasibility:** Bringing it back to our main goal – can Walrus + Sui support ConvictionFi/DeFAI automation? – the answer is a resounding yes. The combination of Walrus for data and Sui for logic creates a unique environment where you don’t have to force all intelligence on-chain (which is hard or impossible for AI-scale logic), but you still maintain on-chain **autonomy and transparency**. Walrus provides the persistence and availability of off-chain inputs (prompts, triggers, models) in a **trust-minimized way** (much more decentralized than a Web2 server or even something like AWS + IPFS). Sui provides the guardrails and finality for financial actions. Real-world adoption, as we’ve outlined, is already validating each piece of this puzzle: dynamic strategy storage, AI integration, automated execution.

Going forward, we can expect even more robust frameworks to emerge – for example, perhaps a **“Strategy Studio” dApp** where users can craft a strategy (filling a form for theme, triggers, etc.), and under the hood it mints an NFT, uploads to Walrus, and deploys an agent. The user might not even realize Walrus is there; they just see their strategy working. That level of abstraction will make ConvictionFi accessible to non-developers. But at the foundation of it all, Walrus will be quietly storing and serving the data that these AI-driven strategies need, and Sui will be executing their trades with precision.

**Sources:**

- Sui + Walrus technical documentation and blog posts for architecture and features.
- Comparisons of Walrus to Arweave/Filecoin (cost, programmability, deletion).
- Walrus integration in Sui’s ecosystem (Sui storage fund, SUI token deflation from Walrus usage).
- Sui Foundation blog on Talus AI agents leveraging Walrus (use cases for models, datasets, history).
- TradePort press release on using Walrus for NFT metadata (dynamic and programmable NFT data).
- Walrus hackathon and community engagement (developer tools, number of participants).
- Official Walrus docs on usage (APIs, public data, CLI) and Medium article on Walrus’s design (RedStuff encoding, blob ID on-chain).
